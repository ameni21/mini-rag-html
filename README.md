# Multi-Source RAG Chatbot

## 🧠 Project Overview

This project is designed to implement a **Retrieval-Augmented Generation (RAG) chatbot** capable of intelligently answering user queries using **three retrieval modes**:

1. 💬 **Native LLM responses** – direct answers generated by the model itself  
2. 🧲 **Vectorstore-based RAG** – powered by a local **Qdrant** (due to issues with installing **ChromaDB** vector store ) and orchestrated with **LangGraph**  
3. 🌐 **Web search-based augmentation** – using external tools such as **Tavily** 

The chatbot dynamically selects the most appropriate retrieval mode based on the **nature of the user’s question**, showcasing **context-awareness** and **adaptive retrieval strategy switching**.


## 🚀 Key Highlights

✅ **Robust PostgreSQL Integration** with seamless data migration using **Alembic** and **SQLAlchemy**  
✅ **Clean model initialization** leveraging **Pydantic** schemas for validation and consistency  
✅ **Scalable semantic search** powered by **Qdrant**, serving as a high-performance vector database  
✅ **Modular LLM Provider Interface** implemented via a factory pattern, enabling easy extensibility and clean code  
✅ **Support for both local and remote LLMs**, including OpenAI and Ollama-based models  
✅ **Custom multilingual prompt templates**, optimized for **Arabic** and **English** use cases  
✅ **MVC-based architecture** ensuring separation of concerns and maintainability  
✅ **End-to-end NLP pipeline**: `Upload ➝ Chunk ➝ Index ➝ Query ➝ Generate Answer`  
✅ **Adaptive RAG Strategy**: intelligent query routing between multiple sources based on content type and relevance.

📘 [Read more: Adaptive RAG strategy using LangGraph (Official Tutorial)](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rag/langgraph_adaptive_rag.ipynb)  
🖼️ Adaptive RAG Routing Overview:  
![Adaptive RAG Strategy](src/assets/images/adaptative_rag_starigie.png)

Supported routes:
- 🌐 **Web Search**: Use this when the question is about real-time or recent topics (e.g., current events, latest research, live data)  
- 🔄 **Self-Corrective RAG**: Use this when the question is about internal documents in artificial intelligence (e.g., reinforcement_learnig, Reccurrent Neural Network, Context Generation ). 
- 🧠 **LLM with internal  data**: Use this when the question is general, open-domain, or casual (e.g., trivia, historic facts, general knowledge).


---



## 📦 Tech Stack

- **FastAPI** — for building a high-performance backend API  
- **PostgreSQL** — for storing and managing structured data  
- **Qdrant** — a scalable and fast vector database for semantic search  
- **LangGraph** — enables dynamic multi-tool RAG orchestration and flow control  
- **LangChain** — used for file parsing (TXT, PDF), document splitting, and web search integration  
- **Pydantic** — for data validation and model definition using Python type hints  
- **SQLAlchemy** — for ORM-based interaction with the PostgreSQL database  
- **Alembic** — for handling database migrations cleanly and efficiently  
- **Docker** — for containerized deployment across different environments



---

## 🧪 Evaluation with LangSmith

We use to trace RAG workflows.

🔍 [View Example Trace](https://smith.langchain.com/public/2ae5ef28-7c59-47b7-b5cd-e9f70596544f/r)


## 📸 Screenshots & Logs

To provide more transparency and help with debugging or understanding system behavior, we've included **screenshots of key issues and successful runs**.

🖼️ You can find these images in the following path:  
`src/assets/images/`

Feel free to check the visuals for:
- Runtime execution examples
- Debug logs
- Graph routing captures
- Error trace screenshots



## Table of Contents
- Requirements
- Installation
- Run the FastAPI server

## (Optional) Steup your command line intrface for better readability
```bash
export PS1="\[\033[01;32m\]\u@\h:\w\n\[\033[00m\]\$ "
```

## Requirements

 Python 3.10 or later

#### Install Dependencies 

```bash 
sudo apt update
sudo apt install libpq-dev gcc python3-dev
```

#### Install Python using pip3

1) install pip 

```bash 
$ sudo apt-get install python3-pip
```

2)  create a new environnement 

```bash
$ python3 -m venv .venv
```

3) Activer l’environnement virtuel 
```bash 
source .venv/bin/activate
```

## Installation


### Install the required packages

```bash 
$ pip install -r requirements.txt
```

### Setup the environment variables
```bash 
$ cp .env.example .env
```
Set your environment variables in the .env file. Like OPENAI_API_KEY value.

### Run Alembic Migration 
```bash
$ alembic upgrade head
```

### Run Docker Compose Services
```bash 
$ cd docker
$ cp .env.example .env
```
*update .env with your credentials

```bash 
$ cd docker
$ sudo docker compose up -d
```

## Run the FastAPI server

```bash
$ uvicorn main:app --reload --host 0.0.0.0 --port 7000
```
